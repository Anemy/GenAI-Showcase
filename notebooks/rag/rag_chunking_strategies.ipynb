{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463fc59e",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/GenAI-Showcase/blob/main/notebooks/evals/ragas-evaluation.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f28a64",
   "metadata": {},
   "source": [
    "# RAG Series Part 3: Data Modeling Strategies for RAG\n",
    "\n",
    "In this notebook, we will explore and evaluate different chunking techniques for RAG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e0bc8",
   "metadata": {},
   "source": [
    "## Step 1: Install required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f403d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain langchain-openai langchain-mongodb langchain-experimental ragas pymongo tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbd26b",
   "metadata": {},
   "source": [
    "## Step 2: Setup pre-requisites\n",
    "\n",
    "- Set the MongoDB connection string. Follow the steps [here](https://www.mongodb.com/docs/manual/reference/connection-string/) to get the connection string from the Atlas UI.\n",
    "\n",
    "- Set the OpenAI API key. Steps to obtain an API key as [here](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9fcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd337af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4f45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_URI = getpass.getpass(\"Enter your MongoDB connection string:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32216846",
   "metadata": {},
   "source": [
    "## Step 3: Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57121b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader(\n",
    "    [\n",
    "        \"https://peps.python.org/pep-0483/\",\n",
    "        \"https://peps.python.org/pep-0008/\",\n",
    "        \"https://peps.python.org/pep-0257/\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "pages = web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255d751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46573da",
   "metadata": {},
   "source": [
    "## Step 4: Define chunking functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defa10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa29d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_token(docs, chunk_size, chunk_overlap):\n",
    "    splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a62e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_split(docs, chunk_size, chunk_overlap):\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=\"cl100k_base\",\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4b0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_python_split(docs, chunk_size, chunk_overlap, language):\n",
    "    splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        language=language,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f05d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_split(docs):\n",
    "    splitter = SemanticChunker(\n",
    "        OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\"\n",
    "    )\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19adb6",
   "metadata": {},
   "source": [
    "## Step 5: Generate the Evaluation Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04aef624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorva.joshi/Documents/GenAI-Showcase/notebooks/rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Filename and doc_id are the same for all nodes.                 \n",
      "Generating: 100%|██████████| 10/10 [01:41<00:00, 10.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)\n",
    "\n",
    "# Change resulting question type distribution\n",
    "distributions = {simple: 0.5, multi_context: 0.4, reasoning: 0.1}\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(pages, 10, distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37b4ade3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the recommended approach for implement...</td>\n",
       "      <td>[ations.\\n\\nComparisons to singletons like Non...</td>\n",
       "      <td>When implementing ordering operations with ric...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://peps.python.org/pep-0008/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the recommended encoding for code in t...</td>\n",
       "      <td>[ in adjacent columns.\\nThe default wrapping i...</td>\n",
       "      <td>Code in the core Python distribution should al...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://peps.python.org/pep-0008/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are function annotations and how are they...</td>\n",
       "      <td>[ presence increases code understandability.\\n...</td>\n",
       "      <td>The Python standard library should be conserva...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://peps.python.org/pep-0008/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the guidelines for writing Pythonic c...</td>\n",
       "      <td>[ be removed.\\nWe don’t use the term “private”...</td>\n",
       "      <td>Public attributes should have no leading under...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://peps.python.org/pep-0008/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the difference between classes and typ...</td>\n",
       "      <td>[ at the top (it has all values)\\nand bottom (...</td>\n",
       "      <td>nan</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'https://peps.python.org/pep-0483/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the recommended approach for implement...   \n",
       "1  What is the recommended encoding for code in t...   \n",
       "2  What are function annotations and how are they...   \n",
       "3  What are the guidelines for writing Pythonic c...   \n",
       "4  What is the difference between classes and typ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ations.\\n\\nComparisons to singletons like Non...   \n",
       "1  [ in adjacent columns.\\nThe default wrapping i...   \n",
       "2  [ presence increases code understandability.\\n...   \n",
       "3  [ be removed.\\nWe don’t use the term “private”...   \n",
       "4  [ at the top (it has all values)\\nand bottom (...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  When implementing ordering operations with ric...         simple   \n",
       "1  Code in the core Python distribution should al...         simple   \n",
       "2  The Python standard library should be conserva...         simple   \n",
       "3  Public attributes should have no leading under...         simple   \n",
       "4                                                nan         simple   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'https://peps.python.org/pep-0008/...          True  \n",
       "1  [{'source': 'https://peps.python.org/pep-0008/...          True  \n",
       "2  [{'source': 'https://peps.python.org/pep-0008/...          True  \n",
       "3  [{'source': 'https://peps.python.org/pep-0008/...          True  \n",
       "4  [{'source': 'https://peps.python.org/pep-0483/...          True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = testset.to_pandas()\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bfd83f",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Chunking Strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18b907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(MONGODB_URI)\n",
    "DB_NAME = \"evals\"\n",
    "COLLECTION_NAME = \"chunking\"\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\"\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac29ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(docs) -> VectorStoreRetriever:\n",
    "    vector_store = MongoDBAtlasVectorSearch.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        collection=MONGODB_COLLECTION,\n",
    "        index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    )\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d534d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics import context_precision, context_recall\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow nested use of asyncio (used by RAGAS)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Disable tqdm locks\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "QUESTIONS = testset.question.to_list()\n",
    "GROUND_TRUTH = testset.ground_truth.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34b66097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eval(docs):\n",
    "    eval_data = {\n",
    "        \"question\": QUESTIONS,\n",
    "        \"ground_truth\": GROUND_TRUTH,\n",
    "        \"contexts\": [],\n",
    "    }\n",
    "\n",
    "    print(f\"Deleting existing documents in the collection {DB_NAME}.{COLLECTION_NAME}\")\n",
    "    MONGODB_COLLECTION.delete_many({})\n",
    "    print(f\"Deletion complete\")\n",
    "    retriever = get_retriever(docs)\n",
    "\n",
    "    # Getting relevant documents for the evaluation dataset\n",
    "    print(f\"Getting contexts for evaluation set\")\n",
    "    for question in tqdm(QUESTIONS):\n",
    "        eval_data[\"contexts\"].append(\n",
    "            [doc.page_content for doc in retriever.similarity_search(question, k=3)]\n",
    "        )\n",
    "    # RAGAS expects a Dataset object\n",
    "    dataset = Dataset.from_dict(eval_data)\n",
    "    # RAGAS runtime settings to avoid hitting OpenAI rate limits\n",
    "    print(f\"Running evals\")\n",
    "    run_config = RunConfig(max_workers=4, max_wait=180)\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[context_precision, context_recall],\n",
    "        run_config=run_config,\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26730cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE: 100\n",
      "------ Fixed token without overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.9000, 'context_recall': 0.8300}\n",
      "------ Fixed token with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:20<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.8500, 'context_recall': 0.7643}\n",
      "------ Recursive with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.9333, 'context_recall': 0.8436}\n",
      "------ Recursive Python splitter with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.9833, 'context_recall': 0.9013}\n",
      "CHUNK SIZE: 200\n",
      "------ Fixed token without overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.8583, 'context_recall': 0.8913}\n",
      "------ Fixed token with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.9500, 'context_recall': 0.8765}\n",
      "------ Recursive with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 1.0000, 'context_recall': 0.8226}\n",
      "------ Recursive Python splitter with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:29<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.8417, 'context_recall': 0.7953}\n",
      "CHUNK SIZE: 500\n",
      "------ Fixed token without overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:17<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.6000, 'context_recall': 0.8209}\n",
      "------ Fixed token with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.5000, 'context_recall': 0.9050}\n",
      "------ Recursive with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:22<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.5583, 'context_recall': 0.8686}\n",
      "------ Recursive Python splitter with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.8833, 'context_recall': 1.0000}\n",
      "CHUNK SIZE: 1000\n",
      "------ Fixed token without overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.6000, 'context_recall': 0.9219}\n",
      "------ Fixed token with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.7583, 'context_recall': 0.9000}\n",
      "------ Recursive with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.8000, 'context_recall': 0.8600}\n",
      "------ Recursive Python splitter with overlap ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [01:24<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.7833, 'context_recall': 0.9000}\n",
      "------ Semantic chunking ------\n",
      "Deleting existing documents in the collection evals.chunking\n",
      "Deletion complete\n",
      "Getting contexts for evaluation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'context_precision': 0.7500, 'context_recall': 0.9000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk_size in [100, 200, 500, 1000]:\n",
    "    chunk_overlap = int(0.15 * chunk_size)\n",
    "    print(f\"CHUNK SIZE: {chunk_size}\")\n",
    "    print(\"------ Fixed token without overlap ------\")\n",
    "    print(f\"Result: {perform_eval(fixed_token(pages, chunk_size, 0))}\")\n",
    "    print(\"------ Fixed token with overlap ------\")\n",
    "    print(f\"Result: {perform_eval(fixed_token(pages, chunk_size, chunk_overlap))}\")\n",
    "    print(\"------ Recursive with overlap ------\")\n",
    "    print(f\"Result: {perform_eval(recursive_split(pages, chunk_size, chunk_overlap))}\")\n",
    "    print(\"------ Recursive Python splitter with overlap ------\")\n",
    "    print(\n",
    "        f\"Result: {perform_eval(recursive_python_split(pages, 4*chunk_size, 4*chunk_overlap, Language.PYTHON))}\"\n",
    "    )\n",
    "print(\"------ Semantic chunking ------\")\n",
    "print(f\"Result: {perform_eval(semantic_split(pages))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
