{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a21319-bef7-4b35-a5c0-09151c738979",
   "metadata": {},
   "source": [
    "# RAG Series Part 1: How to choose the right embedding model for your RAG application\n",
    "\n",
    "This notebook evaluates the [UAE-Large-V1](https://huggingface.co/WhereIsAI/UAE-Large-V1) model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f4997-f3ae-4ba1-9e39-9d9033eb9d43",
   "metadata": {},
   "source": [
    "## Step 1: Install required libraries\n",
    "\n",
    "* **datasets**: Library to get access to datasets available on Hugging Face Hub\n",
    "<p>\n",
    "* **angle-emb**: Library to interact with the AngleE's embedding models\n",
    "<p>\n",
    "* **sentence-transformers**: Framework for working with text and image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8419fcc1-9477-48b0-972b-5b1f64896f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -qU datasets angle-emb sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ed9c1-46a6-4228-b9bd-2af6b246679d",
   "metadata": {},
   "source": [
    "## Step 3: Download the evaluation dataset\n",
    "\n",
    "We will use MongoDB's [cosmopedia-wikihow-chunked](https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked) dataset, which has chunked versions of WikiHow articles from the [Cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia) dataset released by Hugging Face. The dataset is pretty large, so we will only grab the first 25k records for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b0e185-80da-49d8-a457-7a3571e7c919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81030fcd5cb840e6aa67e41069c8a9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = load_dataset(\"MongoDB/cosmopedia-wikihow-chunked\", split=\"train\", streaming=True)\n",
    "data_head = data.take(25000)\n",
    "df = pd.DataFrame(data_head)\n",
    "\n",
    "# Use this if you want the full dataset\n",
    "# data = load_dataset(\"AIatMongoDB/cosmopedia-wikihow-chunked\", split=\"train\")\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be26fb7-1033-4050-ac45-737fbe516703",
   "metadata": {},
   "source": [
    "## Step 4: Data Analysis\n",
    "\n",
    "Make sure the length of the dataset is what we expect (25k), preview the data, drop Nones etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44fc923-dbca-4c1d-88c8-c2a83f6135dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring length of dataset is what we expect i.e. 25k\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c447d5-b4f5-445b-a0e4-9a8635770879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text_token_length</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>Title: How to Create and Maintain a Compost Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>**Step 2: Gather Materials**\\nGather brown (ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>_Key guideline:_ For every volume of green mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>_Key tip:_ Chop large items like branches and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>157</td>\n",
       "      <td>**Step 7: Maturation and Use**\\nAfter 3-4 mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  chunk_id  text_token_length  \\\n",
       "0       0         0                180   \n",
       "1       0         1                141   \n",
       "2       0         2                182   \n",
       "3       0         3                188   \n",
       "4       0         4                157   \n",
       "\n",
       "                                                text  \n",
       "0  Title: How to Create and Maintain a Compost Pi...  \n",
       "1  **Step 2: Gather Materials**\\nGather brown (ca...  \n",
       "2  _Key guideline:_ For every volume of green mat...  \n",
       "3  _Key tip:_ Chop large items like branches and ...  \n",
       "4  **Step 7: Maturation and Use**\\nAfter 3-4 mont...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the contents of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010a03ad-728f-4c7e-870c-b26d124479d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only keep records where the text field is not null\n",
    "df = df[df[\"text\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1555874f-329b-433e-82ff-105ed513314d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4335"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique documents in the dataset\n",
    "df.doc_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46d0c9-5a6c-4dda-9a9d-f97ab04805e6",
   "metadata": {},
   "source": [
    "## Step 5: Creating Embeddings\n",
    "\n",
    "Define embedding functions for each of the models, running sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30251df-1583-4f24-aa38-fe2b19b13ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from angle_emb import AnglE, Prompts\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e861d1b-8e3f-407e-b1ec-faf1ed1d0229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56372a746aac41e2a69397397e2683a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da03ddd9dcbf404dab5a9cc72c463455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884e8858159b436b837368755010778d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff870f9b596b4e7f8b6015865ee16d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960ea09e970a437f80234915911d34cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/733 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c629576c9c4c5994f2ea794245b0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:Prompt is set, the prompt will be automatically applied during the encoding phase. To disable prompt setting, please configure set_prompt(prompt=None)\n"
     ]
    }
   ],
   "source": [
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls').cuda()\n",
    "angle.set_prompt(prompt=Prompts.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbbe5846-659c-49fb-ab57-3afcf577a00a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_angle_embeddings(docs: List[str])-> List[List[float]]:\n",
    "    docs = [{\"text\": doc} for doc in docs]\n",
    "    response = angle.encode(docs, to_numpy=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65184a7d-f2cd-49b5-97e0-b3651bee7606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing embedding using the AnglE embedding model\n",
    "test_angle_embed = get_angle_embeddings([df.iloc[0][\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bc625b-ded3-42e9-96c6-95f864a772ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check to make sure embedding dimensions are as expected i.e. 1024\n",
    "len(test_angle_embed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de671237-a1bc-486f-b51e-c3e8119c3b75",
   "metadata": {},
   "source": [
    "## Step 6: Measuring Embedding Latency\n",
    "\n",
    "Create a local index (list) of embeddings for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760fda68-6893-47fe-a100-b536b2414b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62aecc55-f8e2-4c25-9598-49d49e5fde6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf8622e-51f4-4f11-b1db-4cf24630ae54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba148a00-1dca-4f2d-9f69-803e69be49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    end = min(len(texts), i+batch_size)\n",
    "    batch = texts[i:end]\n",
    "    batch_embeddings = get_angle_embeddings(batch)\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2514e0-cc9d-4203-a3af-53a9fabacb10",
   "metadata": {},
   "source": [
    "## Step 7: Measuring Retrieval Quality\n",
    "\n",
    "* Create embedding for the user query\n",
    "<p>\n",
    "* Get the top 5 most similar documents from the local vector store using dot product as the similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d038aa19-023c-4c1b-9618-df6fd60390cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129e4b7-c2b1-436b-8ef6-fedb28061bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.asarray(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a247168-ab58-41ce-a135-6c2dcd929df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query: str, top_k: int=3):\n",
    "    query_emb = np.asarray(get_angle_embeddings([query]))\n",
    "    scores = cos_sim(query_emb, embeddings)[0]\n",
    "    idxs = np.argsort(-scores)[:3]\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    for idx in idxs:\n",
    "        print(f\"Score: {scores[idx]:.4f}\")\n",
    "        print(texts[idx])\n",
    "        print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a02484-5e0c-41a8-bf15-da08f8e95d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = query(\"Hello World\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
