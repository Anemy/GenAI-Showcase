{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae07b50",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/GenAI-Showcase/blob/main/notebooks/evals/ragas-evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705420ac",
   "metadata": {},
   "source": [
    "# RAG Series Part 2: How to evaluate your RAG application\n",
    "\n",
    "This notebook shows how to evaluate a RAG application using the [RAGAS](https://docs.ragas.io/en/stable/index.html) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c666fbf2",
   "metadata": {},
   "source": [
    "## Step 1: Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f973db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU ragas datasets pandas langchain langchain-mongodb pymongo tqdm langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e9a15",
   "metadata": {},
   "source": [
    "## Step 2: Setup pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98e464",
   "metadata": {},
   "source": [
    "* Set the MongoDB connection string. Follow the steps [here](https://www.mongodb.com/docs/manual/reference/connection-string/) to get the connection string from the Atlas UI.\n",
    "\n",
    "* Set the OpenAI API key. Steps to obtain an API key as [here](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5740a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c0c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195b4d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your MongoDB connection string:········\n"
     ]
    }
   ],
   "source": [
    "MONGODB_URI = getpass.getpass(\"Enter your MongoDB connection string:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99b49b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Anthropic API Key:········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44deb05f",
   "metadata": {},
   "source": [
    "## Step 3: Download the Hugging Face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f1cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf4f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"explodinggradients/ragas-wikiqa\", split=\"train\", streaming=True)\n",
    "data_head = data.take(50)\n",
    "df = pd.DataFrame(data_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8a4c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>incorrect_answer</th>\n",
       "      <th>question_id</th>\n",
       "      <th>generated_with_rag</th>\n",
       "      <th>context</th>\n",
       "      <th>generated_without_rag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
       "      <td>As such, African immigrants are to be distingu...</td>\n",
       "      <td>From the Immigration and Nationality Act of 19...</td>\n",
       "      <td>Q0</td>\n",
       "      <td>\\nAfrican Americans were immigrated to the Uni...</td>\n",
       "      <td>[African immigration to the United States refe...</td>\n",
       "      <td>African Americans were immigrated to the US in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n",
       "\n",
       "                                      correct_answer  \\\n",
       "0  As such, African immigrants are to be distingu...   \n",
       "\n",
       "                                    incorrect_answer question_id  \\\n",
       "0  From the Immigration and Nationality Act of 19...          Q0   \n",
       "\n",
       "                                  generated_with_rag  \\\n",
       "0  \\nAfrican Americans were immigrated to the Uni...   \n",
       "\n",
       "                                             context  \\\n",
       "0  [African immigration to the United States refe...   \n",
       "\n",
       "                               generated_without_rag  \n",
       "0  African Americans were immigrated to the US in...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfa781",
   "metadata": {},
   "source": [
    "## Step 4: Chunk up the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc218dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceed4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    keep_separator=False,\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417f79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(texts):\n",
    "    chunked_texts = []\n",
    "    for text in texts:\n",
    "        chunks = text_splitter.create_documents([text])\n",
    "        chunked_texts.extend([chunk.page_content for chunk in chunks]) \n",
    "    return chunked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3116297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"chunks\"] = df[\"context\"].apply(lambda x: split_texts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc620e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = df[\"chunks\"].tolist()\n",
    "docs = []\n",
    "for chunk in all_chunks:\n",
    "    docs.extend(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c1b9b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19fed721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Figgis had problems because permits were not issued for some street scenes. This caused him to film some scenes on the Las Vegas strip in one take to avoid the police, which Figgis said benefited production and the authenticity of the acting, remarking \"I\\'ve always hated the convention of shooting on a street, and then having to stop the traffic, and then having to tell the actors, \\'Well, there\\'s meant to be traffic here, so you\\'re going to have to shout.\\' And they\\'re shouting, but it\\'s quiet and they feel really stupid, because it\\'s unnatural. You put them up against a couple of trucks, with it all happening around them, and their voices become great\". Filming took place over 28 days.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fd2b3",
   "metadata": {},
   "source": [
    "## Step 5: Create embeddings and ingest them into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6128ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pymongo import MongoClient\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3810090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(\n",
    "    docs: List[str], model: str = \"text-embedding-3-large\"\n",
    ") -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        docs (List[str]): List of texts to embed\n",
    "        model (str, optional): Model name. Defaults to \"text-embedding-3-large\".\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Array of embeddings\n",
    "    \"\"\"\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    docs = [doc.replace(\"\\n\", \" \") for doc in docs]\n",
    "    response = openai_client.embeddings.create(input=docs, model=model)\n",
    "    response = [r.embedding for r in response.data]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f1a433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGODB_URI)\n",
    "DB_NAME = \"ragas_evals\"\n",
    "db = client[DB_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "284c00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccbce870",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_EMBEDDING_MODELS = [\"text-embedding-ada-002\", \"text-embedding-3-small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b604a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting embeddings for the text-embedding-ada-002 model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81e5c1c1fd5404ab4434a6f7325c5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting embeddings for the text-embedding-ada-002 model\n",
      "Inserting embeddings for the text-embedding-ada-002 model\n",
      "Finished inserting embeddings for the text-embedding-ada-002 model\n",
      "Getting embeddings for the text-embedding-3-small model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3d37f8e8274571af11caf535caca76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting embeddings for the text-embedding-3-small model\n",
      "Inserting embeddings for the text-embedding-3-small model\n",
      "Finished inserting embeddings for the text-embedding-3-small model\n"
     ]
    }
   ],
   "source": [
    "for model in EVAL_EMBEDDING_MODELS:\n",
    "    embedded_docs = []\n",
    "    print(f\"Getting embeddings for the {model} model\")\n",
    "    for i in tqdm(range(0, len(docs), batch_size)):\n",
    "        end = min(len(docs), i + batch_size)\n",
    "        batch = docs[i:end]\n",
    "        # Generate embeddings for current batch\n",
    "        batch_embeddings = get_embeddings(batch, model)\n",
    "        batch_embedded_docs = [{\"text\": batch[i], \"embedding\": batch_embeddings[i]} for i in range(len(batch))]\n",
    "        embedded_docs.extend(batch_embedded_docs)\n",
    "    print(f\"Finished getting embeddings for the {model} model\")\n",
    "    \n",
    "    print(f\"Inserting embeddings for the {model} model\")\n",
    "    collection = db[model]\n",
    "    collection.delete_many({})\n",
    "    collection.insert_many(embedded_docs)\n",
    "    print(f\"Finished inserting embeddings for the {model} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a038b19",
   "metadata": {},
   "source": [
    "## Step 6: Compare Embeddings for the Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad8c421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import context_precision, context_recall\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fbdb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(model):\n",
    "    embeddings = OpenAIEmbeddings(model=model)\n",
    "    \n",
    "    vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    connection_string=MONGODB_URI,\n",
    "    namespace=f\"{DB_NAME}.{model}\",\n",
    "    embedding= embeddings,\n",
    "    index_name=\"vector_index\",\n",
    "    text_key=\"text\"\n",
    "    )\n",
    "    \n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2733c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTIONS = df[\"question\"].to_list()\n",
    "GROUND_TRUTH = df[\"correct_answer\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64d1f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb75c416dce49abb1d10e7531653e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6639ea514d12482fbecf1a36b59f067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the text-embedding-ada-002 model: {'context_precision': 0.8580, 'context_recall': 0.9050}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0531cd1bc05d42a3953ff76e600c9c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b0e9004f2644b4bcc170be0368cc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the text-embedding-3-small model: {'context_precision': 0.8586, 'context_recall': 0.9217}\n"
     ]
    }
   ],
   "source": [
    "for model in EVAL_EMBEDDING_MODELS:\n",
    "    data = {\"question\": [], \"ground_truth\": [], \"contexts\": []}\n",
    "    data[\"question\"] = QUESTIONS\n",
    "    data[\"ground_truth\"] = GROUND_TRUTH\n",
    "\n",
    "    retriever = get_retriever(model)\n",
    "    for i in tqdm(range(0, len(QUESTIONS))):\n",
    "        data[\"contexts\"].append([doc.page_content for doc in retriever.get_relevant_documents(QUESTIONS[i])])\n",
    "        \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    \n",
    "    result= evaluate(dataset=dataset, metrics=[context_precision, context_recall])\n",
    "    print(f\"Result for the {model} model: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01417f5",
   "metadata": {},
   "source": [
    "## Step 7: Compare Completion Models for the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7920a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from ragas.metrics import faithfulness, answer_relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44221aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_chain(model):\n",
    "    # Generate context using the retriever, and pass the user question through\n",
    "    retrieve = {\"context\": get_retriever(\"text-embedding-3-small\") | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])), \"question\": RunnablePassthrough()}\n",
    "    template = \"\"\"Answer the question based only on the following context: \\\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    # Defining the chat prompt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # Defining the model to be used for chat completion\n",
    "    if model == \"openai\":\n",
    "        llm = ChatOpenAI(temperature=0)\n",
    "    elif model == \"anthropic\":\n",
    "        llm = ChatAnthropic(temperature=0, anthropic_api_key=\"YOUR_API_KEY\", model_name=\"claude-3-sonnet-20240229\")\n",
    "    # Parse output as a string\n",
    "    parse_output = StrOutputParser()\n",
    "\n",
    "    # Naive RAG chain \n",
    "    rag_chain = (\n",
    "        retrieve\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parse_output\n",
    "    )\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b685ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"anthropic\", \"openai\"]:\n",
    "    data = {\"question\": [], \"ground_truth\": [], \"contexts\": [], \"answer\": []}\n",
    "    data[\"question\"] = QUESTIONS\n",
    "    data[\"ground_truth\"] = GROUND_TRUTH\n",
    "\n",
    "    retriever = get_retriever(\"text-embedding-3-small\")\n",
    "    rag_chain = get_rag_chain(model)\n",
    "    for i in tqdm(range(0, len(QUESTIONS))):\n",
    "        question = QUESTIONS[i]\n",
    "        data[\"answer\"].append(rag_chain.invoke(question))\n",
    "        data[\"contexts\"].append([doc.page_content for doc in retriever.get_relevant_documents(question)])\n",
    "        \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    \n",
    "    result= evaluate(dataset=dataset, metrics=[faithfulness, answer_relevancy])\n",
    "    print(f\"Result for the {model} model: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80816dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
