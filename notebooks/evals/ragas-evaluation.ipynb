{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae07b50",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/GenAI-Showcase/blob/main/notebooks/evals/ragas-evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705420ac",
   "metadata": {},
   "source": [
    "# RAG Series Part 2: How to evaluate your RAG application\n",
    "\n",
    "This notebook shows how to evaluate a RAG application using the [RAGAS](https://docs.ragas.io/en/stable/index.html) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c666fbf2",
   "metadata": {},
   "source": [
    "## Step 1: Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f973db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU ragas datasets pandas langchain langchain-mongodb pymongo tqdm langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e9a15",
   "metadata": {},
   "source": [
    "## Step 2: Setup pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98e464",
   "metadata": {},
   "source": [
    "* Set the MongoDB connection string. Follow the steps [here](https://www.mongodb.com/docs/manual/reference/connection-string/) to get the connection string from the Atlas UI.\n",
    "\n",
    "* Set the OpenAI API key. Steps to obtain an API key as [here](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5740a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c0c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195b4d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your MongoDB connection string:········\n"
     ]
    }
   ],
   "source": [
    "MONGODB_URI = getpass.getpass(\"Enter your MongoDB connection string:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99b49b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Anthropic API Key:········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44deb05f",
   "metadata": {},
   "source": [
    "## Step 3: Download the Hugging Face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f1cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"explodinggradients/ragas-wikiqa\", split=\"train\", streaming=True)\n",
    "data_head = data.take(50)\n",
    "df = pd.DataFrame(data_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e8ffafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"explodinggradients/ragas-wikiqa\", split=\"train\")\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8a4c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>incorrect_answer</th>\n",
       "      <th>question_id</th>\n",
       "      <th>generated_with_rag</th>\n",
       "      <th>context</th>\n",
       "      <th>generated_without_rag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
       "      <td>As such, African immigrants are to be distingu...</td>\n",
       "      <td>From the Immigration and Nationality Act of 19...</td>\n",
       "      <td>Q0</td>\n",
       "      <td>\\nAfrican Americans were immigrated to the Uni...</td>\n",
       "      <td>[African immigration to the United States refe...</td>\n",
       "      <td>African Americans were immigrated to the US in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n",
       "\n",
       "                                      correct_answer  \\\n",
       "0  As such, African immigrants are to be distingu...   \n",
       "\n",
       "                                    incorrect_answer question_id  \\\n",
       "0  From the Immigration and Nationality Act of 19...          Q0   \n",
       "\n",
       "                                  generated_with_rag  \\\n",
       "0  \\nAfrican Americans were immigrated to the Uni...   \n",
       "\n",
       "                                             context  \\\n",
       "0  [African immigration to the United States refe...   \n",
       "\n",
       "                               generated_without_rag  \n",
       "0  African Americans were immigrated to the US in...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa92c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfa781",
   "metadata": {},
   "source": [
    "## Step 4: Chunk up the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc218dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    keep_separator=False,\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(texts):\n",
    "    chunked_texts = []\n",
    "    for text in texts:\n",
    "        chunks = text_splitter.create_documents([text])\n",
    "        chunked_texts.extend([chunk.page_content for chunk in chunks]) \n",
    "    return chunked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3116297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"chunks\"] = df[\"context\"].apply(lambda x: split_texts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc620e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = df[\"chunks\"].tolist()\n",
    "docs = []\n",
    "for chunk in all_chunks:\n",
    "    docs.extend(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fed721",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fd2b3",
   "metadata": {},
   "source": [
    "## Step 5: Create embeddings and ingest them into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd6128ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pymongo import MongoClient\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(\n",
    "    docs: List[str], model: str = \"text-embedding-3-large\"\n",
    ") -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        docs (List[str]): List of texts to embed\n",
    "        model (str, optional): Model name. Defaults to \"text-embedding-3-large\".\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Array of embeddings\n",
    "    \"\"\"\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    docs = [doc.replace(\"\\n\", \" \") for doc in docs]\n",
    "    response = openai_client.embeddings.create(input=docs, model=model)\n",
    "    response = [r.embedding for r in response.data]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1a433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGODB_URI)\n",
    "DB_NAME = \"ragas_evals\"\n",
    "db = client[DB_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284c00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbce870",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_EMBEDDING_MODELS = [\"text-embedding-ada-002\", \"text-embedding-3-small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in EVAL_EMBEDDING_MODELS:\n",
    "    embedded_docs = []\n",
    "    print(f\"Getting embeddings for the {model} model\")\n",
    "    for i in tqdm(range(0, len(docs), batch_size)):\n",
    "        end = min(len(docs), i + batch_size)\n",
    "        batch = docs[i:end]\n",
    "        # Generate embeddings for current batch\n",
    "        batch_embeddings = get_embeddings(batch, model)\n",
    "        batch_embedded_docs = [{\"text\": batch[i], \"embedding\": batch_embeddings[i]} for i in range(len(batch))]\n",
    "        embedded_docs.extend(batch_embedded_docs)\n",
    "    print(f\"Finished getting embeddings for the {model} model\")\n",
    "    \n",
    "    print(f\"Inserting embeddings for the {model} model\")\n",
    "    collection = db[model]\n",
    "    collection.delete_many({})\n",
    "    collection.insert_many(embedded_docs)\n",
    "    print(f\"Finished inserting embeddings for the {model} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a038b19",
   "metadata": {},
   "source": [
    "## Step 6: Compare Embeddings for the Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8c421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics import context_precision, context_recall\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fbdb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(model, k):\n",
    "    embeddings = OpenAIEmbeddings(model=model)\n",
    "    \n",
    "    vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    connection_string=MONGODB_URI,\n",
    "    namespace=f\"{DB_NAME}.{model}\",\n",
    "    embedding= embeddings,\n",
    "    index_name=\"vector_index\",\n",
    "    text_key=\"text\"\n",
    "    )\n",
    "    \n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2733c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTIONS = df[\"question\"].to_list()\n",
    "GROUND_TRUTH = df[\"correct_answer\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d1f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d65366529ee4acdbd9bc7bf25fa814d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f273ca2508e417fae382f5abdaf38c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to parse output. Returning None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the text-embedding-ada-002 model: {'context_precision': 0.9267, 'context_recall': 0.8423}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82971625064746b1b3effe54868cc5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbe45cf420e4f11992cfb93161a9a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the text-embedding-3-small model: {'context_precision': 0.9116, 'context_recall': 0.8806}\n"
     ]
    }
   ],
   "source": [
    "for model in EVAL_EMBEDDING_MODELS:\n",
    "    data = {\"question\": [], \"ground_truth\": [], \"contexts\": []}\n",
    "    data[\"question\"] = QUESTIONS\n",
    "    data[\"ground_truth\"] = GROUND_TRUTH\n",
    "\n",
    "    retriever = get_retriever(model, 2)\n",
    "    for i in tqdm(range(0, len(QUESTIONS))):\n",
    "        data[\"contexts\"].append([doc.page_content for doc in retriever.get_relevant_documents(QUESTIONS[i])])\n",
    "        \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    run_config = RunConfig(max_workers=4, max_wait=180)\n",
    "    result= evaluate(dataset=dataset, metrics=[context_precision, context_recall], run_config=run_config, raise_exceptions=False)\n",
    "    print(f\"Result for the {model} model: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01417f5",
   "metadata": {},
   "source": [
    "## Step 7: Compare Completion Models for the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7920a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from ragas.metrics import faithfulness, answer_relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44221aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_chain(retriever, model):\n",
    "    # Generate context using the retriever, and pass the user question through\n",
    "    retrieve = {\"context\": retriever | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])), \"question\": RunnablePassthrough()}\n",
    "    template = \"\"\"Answer the question based only on the following context: \\\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    # Defining the chat prompt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # Defining the model to be used for chat completion\n",
    "    llm = ChatOpenAI(temperature=0, model=model)\n",
    "    # Parse output as a string\n",
    "    parse_output = StrOutputParser()\n",
    "\n",
    "    # Naive RAG chain \n",
    "    rag_chain = (\n",
    "        retrieve\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parse_output\n",
    "    )\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b685ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12fb08f0763463e976227cd480d24bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a0b9df043d4804afbc11b6df93994e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the gpt-3.5-turbo-1106 model: {'faithfulness': 0.9578, 'answer_relevancy': 0.9162}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d52362520374ba0bfac3603e68e9f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aab79f952743daa45891d91e624ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the gpt-3.5-turbo model: {'faithfulness': 0.9721, 'answer_relevancy': 0.9131}\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\"]:\n",
    "    data = {\"question\": [], \"ground_truth\": [], \"contexts\": [], \"answer\": []}\n",
    "    data[\"question\"] = QUESTIONS\n",
    "    data[\"ground_truth\"] = GROUND_TRUTH\n",
    "\n",
    "    retriever = get_retriever(\"text-embedding-3-small\", 2)\n",
    "    rag_chain = get_rag_chain(retriever, model)\n",
    "    for i in tqdm(range(0, len(QUESTIONS))):\n",
    "        question = QUESTIONS[i]\n",
    "        data[\"answer\"].append(rag_chain.invoke(question))\n",
    "        data[\"contexts\"].append([doc.page_content for doc in retriever.get_relevant_documents(question)])\n",
    "        \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    run_config = RunConfig(max_workers=4, max_wait=180)\n",
    "    result= evaluate(dataset=dataset, metrics=[faithfulness, answer_relevancy], run_config=run_config, raise_exceptions=False)\n",
    "    print(f\"Result for the {model} model: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9d30708",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85a1b1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
       "      <td>As such, African immigrants are to be distingu...</td>\n",
       "      <td>[African immigration to the United States refe...</td>\n",
       "      <td>African Americans were involuntarily brought f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are points on a mortgage</td>\n",
       "      <td>Points, sometimes also called a \"discount poin...</td>\n",
       "      <td>[Discount points, also called mortgage points ...</td>\n",
       "      <td>Points on a mortgage are a form of pre-paid in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how does interlibrary loan work</td>\n",
       "      <td>The user makes a request with their local libr...</td>\n",
       "      <td>[After receiving a request from their patron, ...</td>\n",
       "      <td>Interlibrary loan works by allowing patrons of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHAT IS A FY QUARTER</td>\n",
       "      <td>A fiscal year (or financial year, or sometimes...</td>\n",
       "      <td>[1st quarter: 1 October 2022 – 31 December 202...</td>\n",
       "      <td>A FY quarter refers to a quarter within a fina...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who wrote a rose is a rose is a rose</td>\n",
       "      <td>The sentence \"Rose is a rose is a rose is a ro...</td>\n",
       "      <td>[The sentence \"Rose is a rose is a rose is a r...</td>\n",
       "      <td>Gertrude Stein</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n",
       "1                    what are points on a mortgage   \n",
       "2                  how does interlibrary loan work   \n",
       "3                             WHAT IS A FY QUARTER   \n",
       "4             who wrote a rose is a rose is a rose   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  As such, African immigrants are to be distingu...   \n",
       "1  Points, sometimes also called a \"discount poin...   \n",
       "2  The user makes a request with their local libr...   \n",
       "3  A fiscal year (or financial year, or sometimes...   \n",
       "4  The sentence \"Rose is a rose is a rose is a ro...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [African immigration to the United States refe...   \n",
       "1  [Discount points, also called mortgage points ...   \n",
       "2  [After receiving a request from their patron, ...   \n",
       "3  [1st quarter: 1 October 2022 – 31 December 202...   \n",
       "4  [The sentence \"Rose is a rose is a rose is a r...   \n",
       "\n",
       "                                              answer  faithfulness  \\\n",
       "0  African Americans were involuntarily brought f...           1.0   \n",
       "1  Points on a mortgage are a form of pre-paid in...           1.0   \n",
       "2  Interlibrary loan works by allowing patrons of...           1.0   \n",
       "3  A FY quarter refers to a quarter within a fina...           1.0   \n",
       "4                                     Gertrude Stein           1.0   \n",
       "\n",
       "   answer_relevancy  \n",
       "0          0.902984  \n",
       "1          0.976646  \n",
       "2          0.975809  \n",
       "3          0.943946  \n",
       "4          0.929579  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "618db2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>when did dr.carter g woodson die</td>\n",
       "      <td>Carter Godwin Woodson (December 19, 1875April ...</td>\n",
       "      <td>[Carter G. Woodson was born in New Canton, Vir...</td>\n",
       "      <td>Based on the context provided, there is no inf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "91  when did dr.carter g woodson die   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "91  Carter Godwin Woodson (December 19, 1875April ...   \n",
       "\n",
       "                                             contexts  \\\n",
       "91  [Carter G. Woodson was born in New Canton, Vir...   \n",
       "\n",
       "                                               answer  faithfulness  \\\n",
       "91  Based on the context provided, there is no inf...           NaN   \n",
       "\n",
       "    answer_relevancy  \n",
       "91               0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df[\"answer_relevancy\"] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1555047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Carter G. Woodson was born in New Canton, Virginia, on December 19, 1875, the son of former slaves Anne Eliza (Riddle) and James Henry Woodson. Although his father was illiterate, Carter's mother, Anna, had been taught to read by her mistress. His father, James, during the Civil War, had helped Union soldiers near Richmond, after escaping from his owner, by leading them to Confederate supply stations and warehouses to raid army supplies. Thereafter, and until the war ended, James had\",\n",
       "       'His Washington, D.C. home has been preserved and designated the Carter G. Woodson Home National Historic Site.\\nIn 2002, scholar Molefi Kete Asante named Carter G. Woodson on his list of 100 Greatest African Americans.\\nIn 2015, a bronze statue of Woodson was placed in the park named for him in Washington, D.C.\\nOn February 1, 2018, he was honored with a Google Doodle.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.iloc[91][\"contexts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8a86f",
   "metadata": {},
   "source": [
    "## Step 8: Measure overall performance of the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4c65360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import answer_similarity, answer_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f513dfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d04ab512efb417692c25a8e8c5d7b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d873efeeb87347b2b544abfdea43e790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/464 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall metrics: {'answer_similarity': 0.8889, 'answer_correctness': 0.5981}\n"
     ]
    }
   ],
   "source": [
    "data = {\"question\": [], \"ground_truth\": [], \"answer\": []}\n",
    "data[\"question\"] = QUESTIONS\n",
    "data[\"ground_truth\"] = GROUND_TRUTH\n",
    "\n",
    "retriever = get_retriever(\"text-embedding-3-small\", 2)\n",
    "rag_chain = get_rag_chain(retriever, \"gpt-3.5-turbo\")\n",
    "for i in tqdm(range(0, len(QUESTIONS))):\n",
    "    question = QUESTIONS[i]\n",
    "    data[\"answer\"].append(rag_chain.invoke(question))\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "run_config = RunConfig(max_workers=4, max_wait=180)\n",
    "result= evaluate(dataset=dataset, metrics=[answer_similarity, answer_correctness], run_config=run_config, raise_exceptions=False)\n",
    "print(f\"Overall metrics: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
