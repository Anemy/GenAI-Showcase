{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b4d49e-31a1-4093-9255-9cb8e6f96b0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAG Series Part 1: How to choose the right embedding model for your RAG application\n",
    "\n",
    "This notebook evaluates the [voyage-lite-02-instruct](https://docs.voyageai.com/embeddings/) model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a115b9-68e5-44f7-9ea7-fff56bc9ee59",
   "metadata": {},
   "source": [
    "## Step 1: Install required libraries\n",
    "\n",
    "* **datasets**: Library to get access to datasets available on Hugging Face Hub\n",
    "<p>\n",
    "* **voyageai**: Library to interact with Voyage AI's models via their APIs\n",
    "<p>\n",
    "* **sentence-transformers**: Framework for working with text and image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a999fe13-3eee-4fd8-a9fd-0f2f37171ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -qU datasets voyageai sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd8b3e-984b-4dff-bd7f-615e577a9ef8",
   "metadata": {},
   "source": [
    "## Step 2: Setup pre-requisites\n",
    "\n",
    "Set Voyage API key as environment variable, and initialize the Voyage AI client.\n",
    "\n",
    "Steps to obtain a Voyage AI API Key can be found [here](https://docs.voyageai.com/docs/api-key-and-installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e40d3-852c-4abf-9151-875a1d32e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import voyageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8bcde-c242-4641-a7c8-5f69c60d021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOYAGE_API_KEY = getpass.getpass(\"Voyage API Key:\")\n",
    "voyage_client = voyageai.Client(api_key=VOYAGE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a99a68-a7d2-4657-8f05-ea75f19b6748",
   "metadata": {},
   "source": [
    "## Step 3: Download the evaluation dataset\n",
    "\n",
    "We wil use MongoDB's [cosmopedia-wikihow-chunked](https://huggingface.co/datasets/MongoDB/cosmopedia-wikihow-chunked) dataset, which has chunked versions of WikiHow articles from the [Cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia) dataset released by Hugging Face. The dataset is pretty large, so we will only grab the first 25k records for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862e2db-fec8-4294-ad75-9753e69adc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = load_dataset(\"MongoDB/cosmopedia-wikihow-chunked\", split=\"train\", streaming=True)\n",
    "data_head = data.take(25000)\n",
    "df = pd.DataFrame(data_head)\n",
    "\n",
    "# Use this if you want the full dataset\n",
    "# data = load_dataset(\"AIatMongoDB/cosmopedia-wikihow-chunked\", split=\"train\")\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d329bc-cdb7-4651-bef0-8d2ae09d9e4b",
   "metadata": {},
   "source": [
    "## Step 4: Data Analysis\n",
    "\n",
    "Make sure the length of the dataset is what we expect (25k), preview the data, drop Nones etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0f32d-c6f7-4faa-92e1-fae25e9eb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring length of dataset is what we expect i.e. 25k\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782ab49-3d9d-4f67-8b33-474f02b7e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing the contents of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04563eaf-bbd8-4969-9671-eb5312817402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep records where the text field is not null\n",
    "df = df[df[\"text\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a91c3-2f68-4157-a747-05bbc934d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique documents in the dataset\n",
    "df.doc_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400259f-65ca-4301-a245-7af0b746abf1",
   "metadata": {},
   "source": [
    "## Step 5: Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d936743-f18b-410e-8397-c0acf9c61a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda20d74-7296-40df-ab19-ea63a5b47e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voyage_embeddings(docs: List[str], input_type: str, model:str=\"voyage-lite-02-instruct\") -> List[List[float]]:\n",
    "    response = voyage_client.embed(docs, model=model, input_type=input_type)\n",
    "    return response.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5f1da-f4bd-4551-871e-350d44ed0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_voyageai_embed = get_voyage_embeddings([df.iloc[0][\"text\"]], \"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8cd22-d3e7-45cb-abe1-4993208f1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to make sure embedding dimensions are as expected i.e. 1024\n",
    "len(test_voyageai_embed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7c15a-8d3e-4680-acf1-a61a5be5c998",
   "metadata": {},
   "source": [
    "## Step 6: Measuring Embedding Latency\n",
    "\n",
    "Create a local vector store (list) of embeddings for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0e043-dea1-4fb7-a779-6aeba0c690e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c475e-8f36-4183-997f-c13b2320b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793b764-88ec-4bb6-ae71-52dd06791128",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dc5a1-daed-4ae9-a246-b388b0698e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    end = min(len(texts), i+batch_size)\n",
    "    batch = texts[i:end]\n",
    "    batch_embeddings = get_voyage_embeddings(batch, \"document\")\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3918f00e-b31f-4225-80fd-1761fbf3a3d2",
   "metadata": {},
   "source": [
    "## Step 7: Measuring Retrieval Quality\n",
    "\n",
    "* Create embedding for the user query\n",
    "<p>\n",
    "* Get the top 5 most similar documents from the local vector store using dot product as the similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4806b-7311-4516-aea2-a71230c4f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11c827-5e24-481b-af48-8389b9963bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.asarray(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d9c773-896b-4098-8234-fe77360820c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query: str, top_k: int=3):\n",
    "    query_emb = np.asarray(get_voyage_embeddings([query], \"query\"))\n",
    "    scores = cos_sim(query_emb, embeddings)[0]\n",
    "    idxs = np.argsort(-scores)[:3]\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    for idx in idxs:\n",
    "        print(f\"Score: {scores[idx]:.4f}\")\n",
    "        print(texts[idx])\n",
    "        print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ad9ef-67ad-454d-8fa7-65b1e4a35e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"Hello World\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
